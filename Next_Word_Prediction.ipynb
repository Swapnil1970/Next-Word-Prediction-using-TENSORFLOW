{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6oDDHCvZzmbS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "import time\n",
        "import zipfile\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load and process data\n",
        "def load_data(file_path):\n",
        "  with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    text = zip_ref.read(zip_ref.namelist()[0]).decode('ISO-8859-1')\n",
        "  return text"
      ],
      "metadata": {
        "id": "akfQmRZ6zxXi"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(text, tokenizer, max_sequence_len):\n",
        "  input_sequences = []\n",
        "  for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "      n_gram_sequence = token_list[:i+1]\n",
        "      if len(n_gram_sequence) <= max_sequence_len:\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences"
      ],
      "metadata": {
        "id": "UgVLAK0sD_7L"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "NqNUfS5tG1RV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding the sequences\n",
        "def preprocess_sequences(input_sequences, max_sequence_len):\n",
        "  input_sequences = pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre')\n",
        "  X = input_sequences[:, :-1]\n",
        "  y = input_sequences[:, -1]\n",
        "  y = to_categorical(y, num_classes = vocab_size)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "ovYc9K7stuV-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model building\n",
        "def build_model(vocab_size, max_sequence_len):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 100, input_length = max_sequence_len-1))\n",
        "  model.add(LSTM(150, return_sequences=True))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "7mUvux9HuZnm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "file_path = '/content/archive (1).zip'\n",
        "text = load_data(file_path)"
      ],
      "metadata": {
        "id": "hgjsHbEwvW6A"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "9UujttLEvjxX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create input sequences\n",
        "input_sequences = create_sequences(text, tokenizer, max_sequence_len=5)\n",
        "max_sequence_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "BsD4IdjNyEst"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess sequences\n",
        "X, y = preprocess_sequences(input_sequences, max_sequence_len)\n"
      ],
      "metadata": {
        "id": "kVoXi6q5_Hby"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build model\n",
        "model = build_model(total_words, max_sequence_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQpMUO1DGTFT",
        "outputId": "5ff938e1-1c47-4a77-8d8d-da47669de86e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "early_stop = EarlyStopping(monitor='loss', patience=5)\n",
        "history = model.fit(X, y, epochs=100, verbose=1, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL-fqUflHiwI",
        "outputId": "468334b3-4c06-47a1-aab8-91864bedeb65"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 41ms/step - accuracy: 0.0889 - loss: 7.0735\n",
            "Epoch 2/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 38ms/step - accuracy: 0.1198 - loss: 5.7895\n",
            "Epoch 3/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.1512 - loss: 5.4148\n",
            "Epoch 4/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 37ms/step - accuracy: 0.1718 - loss: 5.0843\n",
            "Epoch 5/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.1866 - loss: 4.8683\n",
            "Epoch 6/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.2034 - loss: 4.6090\n",
            "Epoch 7/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.2119 - loss: 4.4539\n",
            "Epoch 8/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.2193 - loss: 4.3037\n",
            "Epoch 9/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - accuracy: 0.2297 - loss: 4.1443\n",
            "Epoch 10/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.2425 - loss: 3.9942\n",
            "Epoch 11/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.2510 - loss: 3.8650\n",
            "Epoch 12/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.2661 - loss: 3.7100\n",
            "Epoch 13/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - accuracy: 0.2745 - loss: 3.5963\n",
            "Epoch 14/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.2998 - loss: 3.4604\n",
            "Epoch 15/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.3130 - loss: 3.3507\n",
            "Epoch 16/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.3271 - loss: 3.2590\n",
            "Epoch 17/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.3545 - loss: 3.1251\n",
            "Epoch 18/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.3662 - loss: 3.0394\n",
            "Epoch 19/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.3827 - loss: 2.9481\n",
            "Epoch 20/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - accuracy: 0.3987 - loss: 2.8472\n",
            "Epoch 21/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.4232 - loss: 2.7472\n",
            "Epoch 22/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.4312 - loss: 2.6811\n",
            "Epoch 23/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.4406 - loss: 2.6243\n",
            "Epoch 24/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.4617 - loss: 2.5221\n",
            "Epoch 25/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.4752 - loss: 2.4443\n",
            "Epoch 26/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.4900 - loss: 2.3770\n",
            "Epoch 27/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.4993 - loss: 2.3034\n",
            "Epoch 28/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.5123 - loss: 2.2550\n",
            "Epoch 29/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.5154 - loss: 2.2278\n",
            "Epoch 30/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.5307 - loss: 2.1554\n",
            "Epoch 31/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.5410 - loss: 2.1119\n",
            "Epoch 32/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.5484 - loss: 2.0627\n",
            "Epoch 33/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.5509 - loss: 2.0416\n",
            "Epoch 34/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.5626 - loss: 1.9942\n",
            "Epoch 35/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.5671 - loss: 1.9567\n",
            "Epoch 36/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - accuracy: 0.5839 - loss: 1.8799\n",
            "Epoch 37/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.5802 - loss: 1.8802\n",
            "Epoch 38/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.5891 - loss: 1.8319\n",
            "Epoch 39/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.5937 - loss: 1.8112\n",
            "Epoch 40/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.5980 - loss: 1.7830\n",
            "Epoch 41/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6007 - loss: 1.7451\n",
            "Epoch 42/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6047 - loss: 1.7360\n",
            "Epoch 43/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 42ms/step - accuracy: 0.6129 - loss: 1.6916\n",
            "Epoch 44/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.6116 - loss: 1.6860\n",
            "Epoch 45/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.6183 - loss: 1.6547\n",
            "Epoch 46/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - accuracy: 0.6182 - loss: 1.6423\n",
            "Epoch 47/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6261 - loss: 1.6049\n",
            "Epoch 48/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.6257 - loss: 1.6110\n",
            "Epoch 49/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.6298 - loss: 1.5951\n",
            "Epoch 50/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.6335 - loss: 1.5531\n",
            "Epoch 51/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6371 - loss: 1.5363\n",
            "Epoch 52/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.6310 - loss: 1.5419\n",
            "Epoch 53/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.6338 - loss: 1.5235\n",
            "Epoch 54/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.6355 - loss: 1.5228\n",
            "Epoch 55/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6441 - loss: 1.4775\n",
            "Epoch 56/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6388 - loss: 1.4867\n",
            "Epoch 57/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.6408 - loss: 1.4898\n",
            "Epoch 58/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6395 - loss: 1.4729\n",
            "Epoch 59/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6406 - loss: 1.4655\n",
            "Epoch 60/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6428 - loss: 1.4449\n",
            "Epoch 61/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - accuracy: 0.6451 - loss: 1.4360\n",
            "Epoch 62/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.6416 - loss: 1.4487\n",
            "Epoch 63/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.6415 - loss: 1.4295\n",
            "Epoch 64/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.6481 - loss: 1.3979\n",
            "Epoch 65/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.6484 - loss: 1.4020\n",
            "Epoch 66/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.6438 - loss: 1.4271\n",
            "Epoch 67/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6527 - loss: 1.3656\n",
            "Epoch 68/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.6526 - loss: 1.3613\n",
            "Epoch 69/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.6434 - loss: 1.3950\n",
            "Epoch 70/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6442 - loss: 1.4075\n",
            "Epoch 71/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.6440 - loss: 1.3925\n",
            "Epoch 72/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.6458 - loss: 1.3878\n",
            "Epoch 73/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.6468 - loss: 1.3774\n",
            "Epoch 74/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.6519 - loss: 1.3623\n",
            "Epoch 75/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.6474 - loss: 1.3643\n",
            "Epoch 76/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.6504 - loss: 1.3595\n",
            "Epoch 77/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 41ms/step - accuracy: 0.6512 - loss: 1.3433\n",
            "Epoch 78/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.6466 - loss: 1.3651\n",
            "Epoch 79/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.6538 - loss: 1.3390\n",
            "Epoch 80/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.6500 - loss: 1.3343\n",
            "Epoch 81/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.6543 - loss: 1.3298\n",
            "Epoch 82/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - accuracy: 0.6453 - loss: 1.3585\n",
            "Epoch 83/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.6484 - loss: 1.3568\n",
            "Epoch 84/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 42ms/step - accuracy: 0.6507 - loss: 1.3267\n",
            "Epoch 85/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.6493 - loss: 1.3240\n",
            "Epoch 86/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 40ms/step - accuracy: 0.6504 - loss: 1.3196\n",
            "Epoch 87/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 47ms/step - accuracy: 0.6534 - loss: 1.3208\n",
            "Epoch 88/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - accuracy: 0.6453 - loss: 1.3211\n",
            "Epoch 89/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - accuracy: 0.6510 - loss: 1.3247\n",
            "Epoch 90/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 43ms/step - accuracy: 0.6556 - loss: 1.2990\n",
            "Epoch 91/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.6480 - loss: 1.3307\n",
            "Epoch 92/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.6542 - loss: 1.3099\n",
            "Epoch 93/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - accuracy: 0.6508 - loss: 1.3082\n",
            "Epoch 94/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.6496 - loss: 1.3177\n",
            "Epoch 95/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 40ms/step - accuracy: 0.6511 - loss: 1.3019\n",
            "Epoch 96/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 41ms/step - accuracy: 0.6447 - loss: 1.3446\n",
            "Epoch 97/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - accuracy: 0.6472 - loss: 1.3052\n",
            "Epoch 98/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.6522 - loss: 1.2992\n",
            "Epoch 99/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.6520 - loss: 1.3113\n",
            "Epoch 100/100\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.6539 - loss: 1.2960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction function\n",
        "def predict_next_word(seed_text, model, tokenizer, max_sequence_len):\n",
        "  for _ in range(5):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=1)\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n",
        "    seed_text += \" \" + predicted_word\n",
        "  return seed_text"
      ],
      "metadata": {
        "id": "Zqq0mSlGIPy2"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test prediction\n",
        "seed_text = \"What do you\"\n",
        "print(predict_next_word(seed_text, model, tokenizer, max_sequence_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJcYxLsvXjGJ",
        "outputId": "b8e69c99-557e-476d-bf08-fce1f4873db3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you think of the weariness stood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6sEqUZ9UX0-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}